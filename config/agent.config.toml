model_provider = "openai"
model = "gpt-5.3-codex"
model_reasoning_effort = "xhigh"
model_reasoning_summary = "detailed"
model_verbosity = "high"

approval_policy = "never"
sandbox_mode = "danger-full-access"
web_search = "live"

project_doc_auto_load = true
# Keep default prompt bootstrap concise/high-signal.
project_doc_fallback_filenames = ["AGENTS.md"]
project_doc_auto_load_extra_filenames = [
  "docs/repo-map.md",
  "docs/agent-mcp.md",
  "docs/agent-setup.md",
  "docs/agent-gotchas.md",
]
project_doc_max_bytes = 131072

# Shared core system prompt is sourced from SYSTEM_PROMPT.md (see --system-prompt-file).

[profiles.fast]
model_reasoning_effort = "medium"
model_reasoning_summary = "concise"
model_verbosity = "medium"

[profiles.deep]
model_reasoning_effort = "xhigh"
model_reasoning_summary = "detailed"
model_verbosity = "high"

[profiles.spark]
model = "gpt-5.3-codex-spark"
model_reasoning_effort = "high"
model_reasoning_summary = "detailed"
model_verbosity = "high"
model_context_window = 128000
model_auto_compact_token_limit = 80000
tool_output_token_limit = 2000

# Optional MCP retrieval template (disabled until uncommented/configured).
# [mcp_servers.repo_rag]
# command = "my-mcp-rag-server"
# args = ["--stdio"]
# startup_timeout_sec = 20
# tool_timeout_sec = 120

[notice]
hide_full_access_warning = true

[tui]
animations = false
